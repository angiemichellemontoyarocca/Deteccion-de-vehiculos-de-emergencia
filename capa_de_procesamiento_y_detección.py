# -*- coding: utf-8 -*-
"""Copy of Capa de Procesamiento y Detección

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PyVUaIjTzQ0Blj7kLv9l2lTIFYNsobLP
"""

!pip install tensorflow opencv-python ipywidgets

# Importar librerías necesarias
from google.colab import drive
from google.colab.patches import cv2_imshow
from google.colab import files
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

# Montar Google Drive
drive.mount('/content/drive')

# Definir la ruta de la carpeta en Google Drive
dataset_path = "/content/drive/MyDrive/Fundamentos CNN"

# Configuración de parámetros ajustados
IMG_SIZE = 160  # Aumentamos un poco más el tamaño
BATCH_SIZE = 16
EPOCHS = 30

# Verificar la distribución de las clases
def check_class_distribution():
    emergency_path = os.path.join(dataset_path, 'Emergencia')
    non_emergency_path = os.path.join(dataset_path, 'No_Emergencia')

    emergency_count = len(os.listdir(emergency_path))
    non_emergency_count = len(os.listdir(non_emergency_path))

    print(f"Imágenes de vehículos de emergencia: {emergency_count}")
    print(f"Imágenes de vehículos normales: {non_emergency_count}")
    print(f"Proporción emergencia/normal: {emergency_count/non_emergency_count:.2f}")

    return emergency_count, non_emergency_count

# Mostrar información del dataset
print("Información del dataset:")
emergency_count, non_emergency_count = check_class_distribution()

# Calcular class weights para el desbalance
total_images = emergency_count + non_emergency_count
weight_emergency = total_images / (2 * emergency_count)
weight_normal = total_images / (2 * non_emergency_count)
class_weights = {0: weight_normal, 1: weight_emergency}

print("\nPesos de las clases:")
print(f"Peso clase normal: {weight_normal:.2f}")
print(f"Peso clase emergencia: {weight_emergency:.2f}")

# Modelo CNN optimizado con menos parámetros
model = Sequential([
    # Primera capa convolucional
    Conv2D(16, (3, 3), activation='relu', padding='same',
           input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    BatchNormalization(),
    MaxPooling2D(2, 2),  # 64x64

    # Segunda capa convolucional
    Conv2D(32, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(2, 2),  # 32x32
    Dropout(0.25),

    # Tercera capa convolucional
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(2, 2),  # 16x16
    Dropout(0.25),

    # Cuarta capa convolucional
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(2, 2),  # 8x8
    Dropout(0.25),

    # Aplanamos
    Flatten(),

    # Capas densas reducidas
    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
    BatchNormalization(),
    Dropout(0.5),
    Dense(2, activation='softmax')
])

# Compilación con learning rate más bajo
model.compile(
    optimizer=Adam(learning_rate=0.00005),  # Learning rate reducido
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Mostramos el resumen del modelo para verificar las dimensiones
model.summary()

# Data augmentation mejorado
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    fill_mode='nearest',
    brightness_range=[0.9, 1.1]
)


# Callbacks ajustados
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=5,
    min_lr=1e-6,
    verbose=1
)

# Generadores de datos
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="training",
    shuffle=True
)

validation_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="validation"
)

print("Imágenes de entrenamiento:", len(train_generator.filenames))
print("Imágenes de validación:", len(validation_generator.filenames))

# Entrenar el modelo
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    callbacks=[early_stopping, reduce_lr],
    class_weight=class_weights,
    verbose=1
)

# Función de predicción mejorada
def predict_emergency_vehicle(image_path, model, threshold=0.2):  # Umbral ajustado
    img = cv2.imread(image_path)
    if img is None:
        print("Error al cargar la imagen")
        return None, None

    img_original = img.copy()
    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    img_expanded = np.expand_dims(img_resized / 255.0, axis=0)

    prediction = model.predict(img_expanded)
    emergency_prob = prediction[0][1]

    # Aplicar el umbral de decisión
    if emergency_prob > threshold:
        label = f"Vehiculo de Emergencia: {emergency_prob:.2%}"
        color = (0, 0, 255)  # Rojo
    else:
        label = f"Vehiculo Normal: {(1-emergency_prob):.2%}"
        color = (0, 255, 0)  # Verde

    # Añadir texto a la imagen
    cv2.putText(img_original, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                0.8, color, 2, cv2.LINE_AA)

    # Mostrar probabilidades detalladas
    print(f"\nProbabilidades detalladas:")
    print(f"Vehiculo de Emergencia: {emergency_prob:.2%}")
    print(f"Vehiculo Normal: {(1-emergency_prob):.2%}")

    return img_original, prediction

# Guardar el modelo
model_save_path = "/content/drive/MyDrive/Fundamentos CNN/emergency_vehicle_model.keras"
model.save(model_save_path)
print(f"Modelo guardado en: {model_save_path}")

# Función para visualizar resultados del entrenamiento
def plot_training_results(history):
    plt.figure(figsize=(15, 5))

    # Gráfica de precisión
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Precisión en entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Precisión en validación')
    plt.title('Precisión del Modelo')
    plt.xlabel('Época')
    plt.ylabel('Precisión')
    plt.legend()

    # Gráfica de pérdida
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Pérdida en entrenamiento')
    plt.plot(history.history['val_loss'], label='Pérdida en validación')
    plt.title('Pérdida del Modelo')
    plt.xlabel('Época')
    plt.ylabel('Pérdida')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Visualizar resultados del entrenamiento
plot_training_results(history)

# Código para probar el modelo con nuevas imágenes
print("\nSube una imagen para probar el modelo:")
uploaded = files.upload()

for filename in uploaded.keys():
    print(f"\nProcesando imagen: {filename}")
    img_result, pred = predict_emergency_vehicle(filename, model)
    if img_result is not None:
        cv2_imshow(img_result)

from datetime import datetime

# Configurar GPU si está disponible
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)